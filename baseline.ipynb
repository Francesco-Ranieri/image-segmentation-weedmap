{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE\n",
    "\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from metrics import *\n",
    "\n",
    "sys.path.append('data')\n",
    "\n",
    "from data.constants import *\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ChannelAllowed(Enum):\n",
    "    RGB = RGB_CHANNEL,\n",
    "    NDVI = NVDI_CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from data.processing import convert_to_black_and_white\n",
    "\n",
    "\n",
    "def objective(trial, images, ground_truth, channel: ChannelAllowed):\n",
    "\n",
    "    # Define the search space for hyperparameters\n",
    "    threshold  = trial.suggest_int('threshold ', 0, 255)\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    mean_iou = 0\n",
    "\n",
    "    for image_path, ground_truth_path in zip(images, ground_truth):\n",
    "        \n",
    "        image = Image.open(image_path)      \n",
    "        \n",
    "        gt = Image.open(ground_truth_path)\n",
    "        gt = convert_to_black_and_white(image=gt, save_results=False, threshold=1)\n",
    "        gt = transform(gt).squeeze(0)\n",
    "\n",
    "        width, height = image.size\n",
    "        \n",
    "        pixels = list(image.getdata())\n",
    "        vegetation = []\n",
    "        \n",
    "        for pixel in pixels:\n",
    "            \n",
    "            if channel == ChannelAllowed.RGB:\n",
    "                vegetation_index = calculate_exg_index(pixel)\n",
    "            else:\n",
    "                # NDVI\n",
    "                vegetation_index = pixel\n",
    "        \n",
    "            if vegetation_index > threshold:\n",
    "                vegetation.append(1)\n",
    "            else:\n",
    "                vegetation.append(0)\n",
    "\n",
    "        vegetation = torch.tensor(vegetation)\n",
    "        vegetation = vegetation.view(height, width)\n",
    "        \n",
    "        # Calculate the mean IoU\n",
    "        mean_iou += calculate_miou(vegetation, gt, 2)\n",
    "        # print(f\"Mean IoU: {mean_iou/len(images)}\")\n",
    "        \n",
    "    return mean_iou / len(images)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from data.constants import *\n",
    "from data.utils import load_data_path\n",
    "\n",
    "dir_path = f\"{OPTUNA}/{BASELINE}\"\n",
    "data = load_data_path()\n",
    "study_channel = ChannelAllowed.NDVI.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_name = f\"sqlite:///baseline_{study_channel}_separate_images.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drone, drone_dir in data.items():\n",
    "    print(f\"Drone: {drone}\")\n",
    "    for image, image_dir in drone_dir.items():\n",
    "        \n",
    "        tiles = image_dir[TILE][study_channel]\n",
    "        ground_truth = image_dir[GROUND_TRUTH]\n",
    "        pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "        \n",
    "        study = optuna.create_study(study_name=image, direction='maximize', storage=storage_name, pruner=pruner, load_if_exists=True)\n",
    "        study.optimize(lambda trial: objective(trial, tiles, ground_truth, study_channel), n_trials=20)\n",
    "\n",
    "        # Get the best hyperparameters\n",
    "        try:\n",
    "            best_params = study.best_params\n",
    "            print(f\"Best Hyperparameters {image}:\", best_params)\n",
    "        except ValueError:\n",
    "            print(f\"No best hyperparameters found for {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All images togheter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_name = f\"sqlite:///baseline_{study_channel}_all.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge images from different drones\n",
    "\n",
    "tiles = []\n",
    "ground_truth = []\n",
    "images = []\n",
    "\n",
    "for drone, drone_dir in data.items():\n",
    "    for image, image_dir in drone_dir.items():     \n",
    "        images += image   \n",
    "        tiles += image_dir[TILE][study_channel]\n",
    "        ground_truth += image_dir[GROUND_TRUTH]\n",
    "\n",
    "study_name = 'all'\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, direction='maximize', storage=storage_name, pruner=pruner, load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, tiles, ground_truth, study_channel), n_trials=0) \n",
    "# Get the best hyperparameters\n",
    "try:\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best Hyperparameters:\", best_params)\n",
    "except ValueError:\n",
    "    print(f\"No best hyperparameters found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_name = f\"sqlite:///{dir_path}/{study_channel}_test.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge images from different drones\n",
    "\n",
    "tiles = []\n",
    "ground_truth = []\n",
    "images = []\n",
    "\n",
    "for drone, drone_dir in data.items():\n",
    "    for image, image_dir in drone_dir.items():   \n",
    "        if image in ('003', '005'):\n",
    "            images += image   \n",
    "            tiles += image_dir[TILE][study_channel]\n",
    "            ground_truth += image_dir[GROUND_TRUTH]\n",
    "\n",
    "study_name = 'test'\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, direction='maximize', storage=storage_name, pruner=pruner, load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, tiles, ground_truth, study_channel), n_trials=20) \n",
    "# Get the best hyperparameters\n",
    "try:\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best Hyperparameters:\", best_params)\n",
    "except ValueError:\n",
    "    print(f\"No best hyperparameters found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    api_key=\"eI2MJOa5W8d1PcAvxhmyP5VGt\",\n",
    "    project_name=\"weedmap-image-segmentation\",\n",
    "    workspace=\"francesco-ranieri\"\n",
    ")\n",
    "\n",
    "experiment.set_name('baseline_ndvi')\n",
    "experiment.add_tags(['baseline', 'ndvi', 'test'])\n",
    "experiment.log_parameters(best_params)\n",
    "experiment.log_metric('mIOU', study.best_value)\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_name = f\"sqlite:///{dir_path}/{study_channel}_train.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge images from different drones\n",
    "\n",
    "tiles = []\n",
    "ground_truth = []\n",
    "images = []\n",
    "\n",
    "for drone, drone_dir in data.items():\n",
    "    for image, image_dir in drone_dir.items():   \n",
    "        if image not in ('003', '005'):\n",
    "            images += image   \n",
    "            tiles += image_dir[TILE][study_channel]\n",
    "            ground_truth += image_dir[GROUND_TRUTH]\n",
    "\n",
    "study_name = 'train'\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, direction='maximize', storage=storage_name, pruner=pruner, load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, tiles, ground_truth, study_channel), n_trials=20) \n",
    "# Get the best hyperparameters\n",
    "try:\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best Hyperparameters:\", best_params)\n",
    "except ValueError:\n",
    "    print(f\"No best hyperparameters found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    api_key=\"eI2MJOa5W8d1PcAvxhmyP5VGt\",\n",
    "    project_name=\"weedmap-image-segmentation\",\n",
    "    workspace=\"francesco-ranieri\"\n",
    ")\n",
    "\n",
    "experiment.set_name('baseline_train_ndvi')\n",
    "experiment.add_tags(['baseline', 'ndvi', 'train'])\n",
    "experiment.log_parameters(best_params)\n",
    "experiment.log_metric('mIOU', study.best_value)\n",
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
