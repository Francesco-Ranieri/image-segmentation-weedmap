{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING\n",
    "\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from constants import *\n",
    "from common import *\n",
    "from metrics import *\n",
    "\n",
    "sys.path.append(\"data\")\n",
    "from processing import *\n",
    "from data.constants import *\n",
    "from data.utils import load_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data = load_data_path()\n",
    "plot_results = False\n",
    "\n",
    "directory_path = os.path.join(EXPERIMENT_PATH, KMEANS)\n",
    "os.makedirs(directory_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from tqdm import TqdmWarning\n",
    "\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "simplefilter(\"ignore\", category=UserWarning)\n",
    "simplefilter(\"ignore\", category=TqdmWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "\n",
    "num_clusters = 3\n",
    "default_channels = 1\n",
    "kmeans = KMeans(n_clusters=num_clusters, n_init='auto', random_state=SEED)\n",
    "\n",
    "for drone, drone_dir in data.items():\n",
    "    \n",
    "    target_label = 2\n",
    "    \n",
    "    print(f\"- Processing drone: {drone}\")\n",
    "    \n",
    "    drone_dir_path = os.path.join(directory_path, drone)\n",
    "    os.makedirs(drone_dir_path, exist_ok=True)\n",
    "    \n",
    "    for image_dir in drone_dir:  \n",
    "        print(f\"-- Processing image directory: {image_dir}\")\n",
    "        image_dir_path = os.path.join(drone_dir_path, image_dir)\n",
    "        os.makedirs(image_dir_path, exist_ok=True)\n",
    "        \n",
    "        tiles_paths = data[drone][image_dir][TILE]\n",
    "        \n",
    "        for tile_path in tiles_paths:\n",
    "            file_name = os.path.basename(tile_path)\n",
    "            print(f\"--- Processing tile: {file_name}\")    \n",
    "            image = Image.open(tile_path)\n",
    "            image_array = np.array(image)\n",
    "            \n",
    "            shape = image_array.shape\n",
    "            height, width = shape[:2]\n",
    "            try:\n",
    "                channels = shape[2]\n",
    "            except IndexError:\n",
    "                channels = default_channels\n",
    "                target_label = 1\n",
    "            \n",
    "            flattened_image_array = image_array.reshape((height * width, channels))\n",
    "            \n",
    "            # Apply K-means clustering\n",
    "            kmeans.fit(flattened_image_array)\n",
    "            \n",
    "            # Get labels for each pixel\n",
    "            labels = kmeans.predict(flattened_image_array)\n",
    "            # Reshape labels to match the original image shape\n",
    "            labels = labels.reshape((height, width))\n",
    "            \n",
    "            # Save only the green cluster (assuming it's labeled as [target_label])\n",
    "            green_segment = (labels == target_label) * 255  # Multiply by 255 to convert boolean to integer (0 or 255)\n",
    "\n",
    "            # Create a PIL image from the segmented green pixels\n",
    "            green_image = Image.fromarray(green_segment.astype(np.uint8))\n",
    "            \n",
    "            # Save the green segmented image\n",
    "            path = os.path.join(directory_path, drone, image_dir, file_name)\n",
    "            green_image.save(path)\n",
    "            \n",
    "            if plot_results:\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.imshow(green_segment, cmap='Greens')  # Adjust the colormap based on your preference\n",
    "                plt.axis('off')\n",
    "                plt.title('Green Pixels')\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_experiment_files(KMEANS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RedEdge\n",
      "\n",
      "\n",
      "Mean IoU 000: 0.7093120671437876\n",
      "------------------------\n",
      "Mean IoU 001: 0.7071644769642841\n",
      "------------------------\n",
      "Mean IoU 002: 0.6255108296043344\n",
      "------------------------\n",
      "Mean IoU 003: 0.7312779810790923\n",
      "------------------------\n",
      "Mean IoU 004: 0.5891863790332762\n",
      "------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sequoia\n",
      "\n",
      "\n",
      "Mean IoU 005: 0.6395362356355797\n",
      "------------------------\n",
      "Mean IoU 006: 0.6333282222150869\n",
      "------------------------\n",
      "Mean IoU 007: 0.6111489676655485\n",
      "------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "files = os.listdir(directory_path)  # Update the path to 'directory_path' instead of 'KMEANS'\n",
    "drone_dirs = os.listdir(directory_path)  # Update the path to 'directory_path' instead of 'KMEANS'\n",
    "drone_dirs.sort()\n",
    "\n",
    "# Define transformations to convert to a tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts PIL image or numpy.ndarray to a tensor\n",
    "])\n",
    "\n",
    "miou = {}\n",
    "\n",
    "for drone_dir in drone_dirs:\n",
    "    \n",
    "    miou[drone_dir] = {}\n",
    "    print(f\"\\n\\n{drone_dir}\\n\\n\")\n",
    "    \n",
    "    drone_dir_path = os.path.join(directory_path, drone_dir)\n",
    "    images_dir = os.listdir(drone_dir_path)\n",
    "    images_dir.sort()\n",
    "    \n",
    "    for image_dir in images_dir:\n",
    "        \n",
    "        miou[drone_dir][image_dir] = 0\n",
    "        \n",
    "        ground_truths = data[drone_dir][image_dir][GROUND_TRUTH]\n",
    "        \n",
    "        image_dir_path = os.path.join(drone_dir_path, image_dir)\n",
    "        sub_dirs = os.listdir(image_dir_path)\n",
    "        sub_dirs.sort()\n",
    "        \n",
    "        for file_name, ground_truth_path in zip(sub_dirs, ground_truths):\n",
    "            \n",
    "            image_path = os.path.join(directory_path, drone_dir, image_dir, file_name)\n",
    "            output = resize_image(file_path=image_path)\n",
    "            output = convert_to_black_and_white(output, False, 128)\n",
    "            outputs = transform(output)  # Example predicted masks\n",
    "\n",
    "            if plot_results:\n",
    "                plt.imshow(output)\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "            gt = Image.open(ground_truth_path)\n",
    "            gt = convert_to_black_and_white(image=gt, save_results=False, threshold=128)\n",
    "            labels = transform(gt)\n",
    "\n",
    "            if plot_results:\n",
    "                plt.imshow(gt)\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                print(\"Output shape:\", outputs.shape)\n",
    "                print(\"Label shape:\", labels.shape)\n",
    "\n",
    "\n",
    "            num_classes = 2  # Number of classes (including background)\n",
    "\n",
    "            miou[drone_dir][image_dir] += calculate_miou(outputs, labels, num_classes)\n",
    "        miou[drone_dir][image_dir] /= len(ground_truths)\n",
    "        print(f\"Mean IoU {image_dir}:\", miou[drone_dir][image_dir])\n",
    "            \n",
    "        print(\"------------------------\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miou[drone_dir][image_dir]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
